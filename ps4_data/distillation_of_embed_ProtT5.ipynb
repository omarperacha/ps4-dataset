{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMoeBQnUCK_E"
      },
      "outputs": [],
      "source": [
        "#@title Install requirements. { display-mode: \"form\" }\n",
        "# Install requirements\n",
        "!pip install torch transformers sentencepiece h5py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set up working directories and download files/checkpoints. { display-mode: \"form\" }\n",
        "# Create directory for storing model weights (2.3GB) and example sequences.\n",
        "# Here we use the encoder-part of ProtT5-XL-U50 in half-precision (fp16) as \n",
        "# it performed best in our benchmarks (also outperforming ProtBERT-BFD).\n",
        "# Also download secondary structure prediction checkpoint to show annotation extraction from embeddings\n",
        "!mkdir protT5 # root directory for storing checkpoints, results etc\n",
        "!mkdir protT5/protT5_checkpoint # directory holding the ProtT5 checkpoint\n",
        "!mkdir protT5/sec_struct_checkpoint # directory storing the supervised classifier's checkpoint\n",
        "!mkdir protT5/output # directory for storing your embeddings & predictions\n",
        "!wget -nc -P protT5/ https://rostlab.org/~deepppi/example_seqs.fasta\n",
        "# Huge kudos to the bio_embeddings team here! We will integrate the new encoder, half-prec ProtT5 checkpoint soon\n",
        "!wget -nc -P protT5/sec_struct_checkpoint http://data.bioembeddings.com/public/embeddings/feature_models/t5/secstruct_checkpoint.pt"
      ],
      "metadata": {
        "id": "tRe7CfuqFFmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In the following you can define your desired output. Current options:\n",
        "# per_residue embeddings\n",
        "# per_protein embeddings\n",
        "# secondary structure predictions\n",
        "\n",
        "# Replace this file with your own (multi-)FASTA\n",
        "# Headers are expected to start with \">\";\n",
        "seq_path = \"./protT5/data.fasta\"\n",
        "\n",
        "# whether to retrieve embeddings for each residue in a protein \n",
        "# --> Lx1024 matrix per protein with L being the protein's length\n",
        "# as a rule of thumb: 1k proteins require around 1GB RAM/disk\n",
        "per_residue = True \n",
        "per_residue_path = \"./protT5/output/per_residue_embeddings\" # where to store the embeddings\n",
        "\n",
        "# whether to retrieve per-protein embeddings \n",
        "# --> only one 1024-d vector per protein, irrespective of its length\n",
        "per_protein = False\n",
        "per_protein_path = \"./protT5/output/per_protein_embeddings.h5\" # where to store the embeddings\n",
        "\n",
        "# whether to retrieve secondary structure predictions\n",
        "# This can be replaced by your method after being trained on ProtT5 embeddings\n",
        "sec_struct = False\n",
        "sec_struct_path = \"./protT5/output/ss3_preds.fasta\" # file for storing predictions\n",
        "\n",
        "# make sure that either per-residue or per-protein embeddings are stored\n",
        "assert per_protein is True or per_residue is True or sec_struct is True, print(\n",
        "    \"Minimally, you need to active per_residue, per_protein or sec_struct. (or any combination)\")\n"
      ],
      "metadata": {
        "id": "ZQotVM94S7NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import dependencies and check whether GPU is available. { display-mode: \"form\" }\n",
        "from transformers import T5EncoderModel, T5Tokenizer\n",
        "import torch\n",
        "import h5py\n",
        "import time\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using {}\".format(device))"
      ],
      "metadata": {
        "id": "ET2v51slC5ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Network architecture for secondary structure prediction. { display-mode: \"form\" }\n",
        "# Convolutional neural network (two convolutional layers) to predict secondary structure\n",
        "class ConvNet( torch.nn.Module ):\n",
        "    def __init__( self ):\n",
        "        super(ConvNet, self).__init__()\n",
        "        # This is only called \"elmo_feature_extractor\" for historic reason\n",
        "        # CNN weights are trained on ProtT5 embeddings\n",
        "        self.elmo_feature_extractor = torch.nn.Sequential(\n",
        "                        torch.nn.Conv2d( 1024, 32, kernel_size=(7,1), padding=(3,0) ), # 7x32\n",
        "                        torch.nn.ReLU(),\n",
        "                        torch.nn.Dropout( 0.25 ),\n",
        "                        )\n",
        "        n_final_in = 32\n",
        "        self.dssp3_classifier = torch.nn.Sequential(\n",
        "                        torch.nn.Conv2d( n_final_in, 3, kernel_size=(7,1), padding=(3,0)) # 7\n",
        "                        )\n",
        "        \n",
        "        self.dssp8_classifier = torch.nn.Sequential(\n",
        "                        torch.nn.Conv2d( n_final_in, 8, kernel_size=(7,1), padding=(3,0))\n",
        "                        )\n",
        "        self.diso_classifier = torch.nn.Sequential(\n",
        "                        torch.nn.Conv2d( n_final_in, 2, kernel_size=(7,1), padding=(3,0))\n",
        "                        )\n",
        "        \n",
        "\n",
        "    def forward( self, x):\n",
        "        # IN: X = (B x L x F); OUT: (B x F x L, 1)\n",
        "        x = x.permute(0,2,1).unsqueeze(dim=-1) \n",
        "        x         = self.elmo_feature_extractor(x) # OUT: (B x 32 x L x 1)\n",
        "        d3_Yhat   = self.dssp3_classifier( x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 3)\n",
        "        d8_Yhat   = self.dssp8_classifier( x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 8)\n",
        "        diso_Yhat = self.diso_classifier(  x ).squeeze(dim=-1).permute(0,2,1) # OUT: (B x L x 2)\n",
        "        return d3_Yhat, d8_Yhat, diso_Yhat"
      ],
      "metadata": {
        "id": "c5XqIyeNStZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load the checkpoint for secondary structure prediction. { display-mode: \"form\" }\n",
        "def load_sec_struct_model():\n",
        "  checkpoint_dir=\"./protT5/sec_struct_checkpoint/secstruct_checkpoint.pt\"\n",
        "  state = torch.load( checkpoint_dir )\n",
        "  model = ConvNet()\n",
        "  model.load_state_dict(state['state_dict'])\n",
        "  model = model.eval()\n",
        "  model = model.to(device)\n",
        "  print('Loaded sec. struct. model from epoch: {:.1f}'.format(state['epoch']))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "YLYFPAT_VLAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load encoder-part of ProtT5 in half-precision. { display-mode: \"form\" }\n",
        "# Load ProtT5 in half-precision (more specifically: the encoder-part of ProtT5-XL-U50) \n",
        "def get_T5_model():\n",
        "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
        "    model = model.to(device) # move model to GPU\n",
        "    model = model.eval() # set model to evaluation model\n",
        "    tokenizer = T5Tokenizer.from_pretrained('Rostlab/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
        "\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "tLDz6jv1C0UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Read in file in fasta format. { display-mode: \"form\" }\n",
        "def read_fasta( fasta_path, split_char=\"|\", id_field=1):\n",
        "    '''\n",
        "        Reads in fasta file containing multiple sequences.\n",
        "        Split_char and id_field allow to control identifier extraction from header.\n",
        "        E.g.: set split_char=\"|\" and id_field=1 for SwissProt/UniProt Headers.\n",
        "        Returns dictionary holding multiple sequences or only single \n",
        "        sequence, depending on input file.\n",
        "    '''\n",
        "    \n",
        "    seqs = dict()\n",
        "    with open( fasta_path, 'r' ) as fasta_f:\n",
        "        for line in fasta_f:\n",
        "            # get pdb ID from header and create new entry\n",
        "            if line.startswith('>'):\n",
        "                pdb_id = line.replace('>', '').strip().split(split_char)\n",
        "                pdb_id = pdb_id[id_field].lower() + pdb_id[id_field+1]\n",
        "                # replace tokens that are mis-interpreted when loading h5\n",
        "                pdb_id = pdb_id.replace(\"/\",\"_\").replace(\".\",\"_\")\n",
        "                seqs[ pdb_id ] = ''\n",
        "            else:\n",
        "                # repl. all whie-space chars and join seqs spanning multiple lines, drop gaps and cast to upper-case\n",
        "                seq= ''.join( line.split() ).upper().replace(\"-\",\"\")\n",
        "                # repl. all non-standard AAs and map them to unknown/X\n",
        "                seq = seq.replace('U','X').replace('Z','X').replace('O','X')\n",
        "                seqs[ pdb_id ] += seq \n",
        "    example_id=next(iter(seqs))\n",
        "    print(\"Read {} sequences.\".format(len(seqs)))\n",
        "    print(\"Example:\\n{}\\n{}\".format(example_id,seqs[example_id]))\n",
        "\n",
        "    return seqs"
      ],
      "metadata": {
        "id": "6OC1toF1EM9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate embeddings. { display-mode: \"form\" }\n",
        "# Generate embeddings via batch-processing\n",
        "# per_residue indicates that embeddings for each residue in a protein should be returned.\n",
        "# per_protein indicates that embeddings for a whole protein should be returned (average-pooling)\n",
        "# max_residues gives the upper limit of residues within one batch\n",
        "# max_seq_len gives the upper sequences length for applying batch-processing\n",
        "# max_batch gives the upper number of sequences per batch\n",
        "def get_embeddings( model, tokenizer, seqs, per_residue, per_protein, sec_struct, \n",
        "                   max_residues=4000, max_seq_len=1000, max_batch=100 ):\n",
        "\n",
        "    if sec_struct:\n",
        "      sec_struct_model = load_sec_struct_model()\n",
        "\n",
        "    results = {\"residue_embs\" : dict(), \n",
        "               \"protein_embs\" : dict(),\n",
        "               \"sec_structs\" : dict() \n",
        "               }\n",
        "\n",
        "    # sort sequences according to length (reduces unnecessary padding --> speeds up embedding)\n",
        "    seq_dict   = sorted( seqs.items(), key=lambda kv: len( seqs[kv[0]] ), reverse=True )\n",
        "    start = time.time()\n",
        "    batch = list()\n",
        "    for seq_idx, (pdb_id, seq) in enumerate(seq_dict,1):\n",
        "        seq = seq\n",
        "        seq_len = len(seq)\n",
        "        seq = ' '.join(list(seq))\n",
        "        batch.append((pdb_id,seq,seq_len))\n",
        "\n",
        "        # count residues in current batch and add the last sequence length to\n",
        "        # avoid that batches with (n_res_batch > max_residues) get processed \n",
        "        n_res_batch = sum([ s_len for  _, _, s_len in batch ]) + seq_len \n",
        "        if len(batch) >= max_batch or n_res_batch>=max_residues or seq_idx==len(seq_dict) or seq_len>max_seq_len:\n",
        "            pdb_ids, seqs, seq_lens = zip(*batch)\n",
        "            batch = list()\n",
        "\n",
        "            # add_special_tokens adds extra token at the end of each sequence\n",
        "            token_encoding = tokenizer.batch_encode_plus(seqs, add_special_tokens=True, padding=\"longest\")\n",
        "            input_ids      = torch.tensor(token_encoding['input_ids']).to(device)\n",
        "            attention_mask = torch.tensor(token_encoding['attention_mask']).to(device)\n",
        "            \n",
        "            try:\n",
        "                with torch.no_grad():\n",
        "                    # returns: ( batch-size x max_seq_len_in_minibatch x embedding_dim )\n",
        "                    embedding_repr = model(input_ids, attention_mask=attention_mask)\n",
        "            except RuntimeError:\n",
        "                print(\"RuntimeError during embedding for {} (L={})\".format(pdb_id, seq_len))\n",
        "                continue\n",
        "\n",
        "            if sec_struct: # in case you want to predict secondary structure from embeddings\n",
        "              d3_Yhat, d8_Yhat, diso_Yhat = sec_struct_model(embedding_repr.last_hidden_state)\n",
        "\n",
        "\n",
        "            for batch_idx, identifier in enumerate(pdb_ids): # for each protein in the current mini-batch\n",
        "                s_len = seq_lens[batch_idx]\n",
        "                # slice off padding --> batch-size x seq_len x embedding_dim  \n",
        "                emb = embedding_repr.last_hidden_state[batch_idx,:s_len]\n",
        "                if sec_struct: # get classification results\n",
        "                    results[\"sec_structs\"][identifier] = torch.max( d3_Yhat[batch_idx,:s_len], dim=1 )[1].detach().cpu().numpy().squeeze()\n",
        "                if per_residue: # store per-residue embeddings (Lx1024)\n",
        "                    results[\"residue_embs\"][ identifier ] = emb.detach().cpu().numpy().squeeze()\n",
        "                    print(\"emb_count:\", len(results[\"residue_embs\"]))\n",
        "                if per_protein: # apply average-pooling to derive per-protein embeddings (1024-d)\n",
        "                    protein_emb = emb.mean(dim=0)\n",
        "                    results[\"protein_embs\"][identifier] = protein_emb.detach().cpu().numpy().squeeze()\n",
        "\n",
        "\n",
        "    passed_time=time.time()-start\n",
        "    avg_time = passed_time/len(results[\"residue_embs\"]) if per_residue else passed_time/len(results[\"protein_embs\"])\n",
        "    print('\\n############# EMBEDDING STATS #############')\n",
        "    print('Total number of per-residue embeddings: {}'.format(len(results[\"residue_embs\"])))\n",
        "    print('Total number of per-protein embeddings: {}'.format(len(results[\"protein_embs\"])))\n",
        "    print(\"Time for generating embeddings: {:.1f}[m] ({:.3f}[s/protein])\".format(\n",
        "        passed_time/60, avg_time ))\n",
        "    print('\\n############# END #############')\n",
        "    return results"
      ],
      "metadata": {
        "id": "nK4hwGggR_Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#@title Write embeddings to disk. { display-mode: \"form\" }\n",
        "def save_embeddings(emb_dict,out_path):\n",
        "    np.savez_compressed(out_path, **emb_dict)"
      ],
      "metadata": {
        "id": "UB6yhwunTymY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Write predictions to disk. { display-mode: \"form\" }\n",
        "def write_prediction_fasta(predictions, out_path):\n",
        "  class_mapping = {0:\"H\",1:\"E\",2:\"L\"} \n",
        "  with open(out_path, 'w+') as out_f:\n",
        "      out_f.write( '\\n'.join( \n",
        "          [ \">{}\\n{}\".format( \n",
        "              seq_id, ''.join( [class_mapping[j] for j in yhat] )) \n",
        "          for seq_id, yhat in predictions.items()\n",
        "          ] \n",
        "            ) )\n",
        "  return None"
      ],
      "metadata": {
        "id": "juXcP5Tpbeqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the encoder part of ProtT5-XL-U50 in half-precision (recommended)\n",
        "model, tokenizer = get_T5_model()\n",
        "\n",
        "# Load example fasta.\n",
        "all_seqs = read_fasta( seq_path )\n",
        "\n",
        "chunk_size = 1000\n",
        "\n",
        "# Compute embeddings and/or secondary structure predictions\n",
        "for i in range(0, len(all_seqs), chunk_size):\n",
        "  keys = list(all_seqs.keys())[i: chunk_size+i]\n",
        "  seqs = {k: all_seqs[k] for k in keys}\n",
        "  results = get_embeddings( model, tokenizer, seqs,\n",
        "                          per_residue, per_protein, sec_struct)\n",
        "\n",
        "  # Store per-residue embeddings\n",
        "  if per_residue:\n",
        "    save_embeddings(results[\"residue_embs\"], per_residue_path + f\"{i}.npz\")"
      ],
      "metadata": {
        "id": "-UKa6VWeE6kC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}